{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Major Project: Movie Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheMonarch00/Movie-Reviews-Sentiment-Analysis/blob/main/Major_Project_Movie_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT8k-Rr_oQfY"
      },
      "source": [
        "# Importing required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2yBp04JdP4z"
      },
      "source": [
        "# For scientific computations\r\n",
        "import numpy as np \r\n",
        "# Loading dataset file\r\n",
        "import pandas as pd \r\n",
        "# To use Regular expression\r\n",
        "import re  \r\n",
        "# Visualization\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3H5aAIboagH"
      },
      "source": [
        "# Reading the datset\r\n",
        "Displaying dataset dimensions, shape, content summary etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbkTjTxjbsEf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyXeypsNeGGt",
        "outputId": "31551b2c-9cdc-48fd-9016-60403fffdd30"
      },
      "source": [
        "dataset = pd.read_table('/content/drive/MyDrive/Internship_ml/moviereviews.tsv')\r\n",
        "print(\"Shape:\",dataset.shape)  ### Return the shape of data \r\n",
        "print(\"Dimensions:\",dataset.ndim)   ### Return the n dimensions of data\r\n",
        "print(\"Size:\",dataset.size)   ### Return the size of data \r\n",
        "print(\"Count of empty fields:\\n\",dataset.isna().sum())  ### Returns the sum fo all na values\r\n",
        "print(\"Summary of dataset:\")\r\n",
        "print(dataset.info())  ### Give concise summary of a DataFrame\r\n",
        "print(\"Top 5 reviews:\\n\",dataset.head())  ## top 5 rows of the dataframe\r\n",
        "print(\"Last 5 reviews:\\n\",dataset.tail()) ## bottom 5 rows of the dataframe"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (25000, 3)\n",
            "Dimensions: 2\n",
            "Size: 75000\n",
            "Count of empty fields:\n",
            " id           0\n",
            "sentiment    0\n",
            "review       0\n",
            "dtype: int64\n",
            "Summary of dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         25000 non-null  object\n",
            " 1   sentiment  25000 non-null  int64 \n",
            " 2   review     25000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.1+ KB\n",
            "None\n",
            "Top 5 reviews:\n",
            "        id  sentiment                                             review\n",
            "0  5814_8          1  With all this stuff going down at the moment w...\n",
            "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
            "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
            "3  3630_4          0  It must be assumed that those who praised this...\n",
            "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
            "Last 5 reviews:\n",
            "             id  sentiment                                             review\n",
            "24995   3453_3          0  It seems like more consideration has gone into...\n",
            "24996   5064_1          0  I don't believe they made this film. Completel...\n",
            "24997  10905_3          0  Guy is a loser. Can't get girls, needs to buil...\n",
            "24998  10194_3          0  This 30 minute documentary Bu√±uel made in the ...\n",
            "24999   8478_8          1  I saw this movie as a child and it broke my he...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Lmx9b87HUvNH",
        "outputId": "ae9a51d7-01e0-4fd3-eab0-58357d0f2ad0"
      },
      "source": [
        "# Find if dataset is balanced or imbalanced (it is balanced)\r\n",
        "sns.countplot('sentiment',data=dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb2a4fb5b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4fU180WpdsP"
      },
      "source": [
        "# Cleaning up the reviews\r\n",
        "\r\n",
        "\r\n",
        "*   Using regular expressions to replace , by white spaces \r\n",
        "*   Tokenisation\r\n",
        "*   Set stopwords and remove them from the review\r\n",
        "*   Append unique words to corpus list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbRvNJipeuix"
      },
      "source": [
        "corpus = []\r\n",
        "# We have 25000 reviews\r\n",
        "for i in range(0,25000):   \r\n",
        "     review = re.sub('[^a-zA-Z]',\" \",dataset[\"review\"][i])\r\n",
        "     review = review.lower()\r\n",
        "     review = review.split()\r\n",
        "     # Stopwords are commonly occuring words with no effect on sentiment\r\n",
        "     all_stopword = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\r\n",
        "     # Keep only non-stop words\r\n",
        "     review = [word for word in review if not word in set(all_stopword)]\r\n",
        "     review = \" \".join(review)\r\n",
        "     corpus.append(review)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM0HmvyRtvSB"
      },
      "source": [
        "Count vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEIv3wEAfZBe"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "# Max features (1500) columns are read\r\n",
        "cv = CountVectorizer(max_features=1500)\r\n",
        "X = cv.fit_transform(corpus).toarray()\r\n",
        "y = dataset[\"sentiment\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7cbChpStyo8"
      },
      "source": [
        "# Creating a model\r\n",
        "Split dataset into training and testing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSWl393fuHG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfiMXtRcuVy5"
      },
      "source": [
        "Applying Gaussian and Multinomial Navie Bayes model to dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTOVedRvfxpQ"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\r\n",
        "GNB = GaussianNB()\r\n",
        "MNB = MultinomialNB()\r\n",
        "model1 = GNB.fit(X_train, y_train)\r\n",
        "model2 = MNB.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0qe7GD7unhH"
      },
      "source": [
        "Choosing model with better accuracy for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSin0D5sgbWQ",
        "outputId": "de72d363-6142-4159-ab2e-d6153de5328e"
      },
      "source": [
        "print(\"Accuracy of Gaussian:\",GNB.score(X_test,y_test))   ## 0.796\r\n",
        "print(\"Accuracy of Multinomial:\",MNB.score(X_test,y_test))   ## 0.8502"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Gaussian: 0.796\n",
            "Accuracy of Multinomial: 0.8502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsW5Pev8uw5W"
      },
      "source": [
        "# Predicting output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iesxG0SFggVs",
        "outputId": "4f7f9ba1-1bcf-4216-b6c8-9f8af69b2f9f"
      },
      "source": [
        "y_pred=model2.predict(X_test)\r\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), np.array(y_test).reshape(len(y_test),1)),1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " ...\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsvI-sBLxaeg"
      },
      "source": [
        "# Evaluating model metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW5EjyMBgnwp",
        "outputId": "c4d08ab3-313d-4999-d9fa-8b536a09ed4a"
      },
      "source": [
        "# Evaluate based on accuracy, classification report and confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "score = accuracy_score(y_test,y_pred)\r\n",
        "cl_report = classification_report(y_test,y_pred)\r\n",
        "print(\"Confusion matrix:\\n\",cm)\r\n",
        "print(\"Classification Report:\\n\",cl_report)\r\n",
        "print(\"Accuracy of MNB: \",score*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            " [[2151  397]\n",
            " [ 352 2100]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85      2548\n",
            "           1       0.84      0.86      0.85      2452\n",
            "\n",
            "    accuracy                           0.85      5000\n",
            "   macro avg       0.85      0.85      0.85      5000\n",
            "weighted avg       0.85      0.85      0.85      5000\n",
            "\n",
            "Accuracy of MNB:  85.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm4-k7bHxeEq"
      },
      "source": [
        "Save model as pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhZ-qIYog6W-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357a38f9-a2bb-46ed-d38e-b199027ac49d"
      },
      "source": [
        "import pickle\r\n",
        "# Save trained model and CountVectorizer to pickle\r\n",
        "pickle.dump(cv, open('countvectorizer.pkl', 'wb'))\r\n",
        "pickle.dump(model2, open(\"MNBmodel.pkl\", \"wb\"))\r\n",
        "# Open trained model and re-evaluate\r\n",
        "loaded_model = pickle.load(open(\"MNBmodel.pkl\", \"rb\"))\r\n",
        "y_pred_new = loaded_model.predict(X_test)\r\n",
        "print(\"Accuracy score: \",loaded_model.score(X_test,y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-7Q-zaTxh5H"
      },
      "source": [
        "Predict output for user entered review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVp4ikqNhODP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6cb9ce-07bd-487f-ab8a-ab218606422b"
      },
      "source": [
        "# Predict output for new review\r\n",
        "def new_review(new_review):\r\n",
        "  cv = pickle.load(open(\"countvectorizer.pkl\",\"rb\"))\r\n",
        "  loaded_model = pickle.load(open(\"MNBmodel.pkl\", \"rb\"))\r\n",
        "  new_review = new_review\r\n",
        "  # Replace , by white spaces in the input review\r\n",
        "  new_review = re.sub('[^a-zA-Z]', ' ', new_review)\r\n",
        "  # Convert to lower case\r\n",
        "  new_review = new_review.lower()\r\n",
        "  # Separate words from text in review\r\n",
        "  new_review = new_review.split()\r\n",
        "  # Generate stop words in english\r\n",
        "  all_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\r\n",
        "  # If word in review is not a stop word, add to corpus list\r\n",
        "  new_review = [word for word in new_review if not word in set(all_stopwords)]\r\n",
        "  new_review = ' '.join(new_review)\r\n",
        "  new_corpus = [new_review]\r\n",
        "  # Convert to binary form\r\n",
        "  new_X_test = cv.transform(new_corpus).toarray()\r\n",
        "  # Predict sentiment for review\r\n",
        "  new_y_pred = loaded_model.predict(new_X_test)\r\n",
        "  return new_y_pred\r\n",
        "\r\n",
        "# User input\r\n",
        "input_review = input('Enter new review:')\r\n",
        "new_review = new_review(input_review)\r\n",
        "# Display results to user\r\n",
        "if new_review[0]==1:\r\n",
        "   print(\"Positive\")\r\n",
        "else :\r\n",
        "   print(\"Negative\")\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter new review:worth the money\n",
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_31jkAxmis"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrN67Q_BhsXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e7b8f3a-953a-47f8-c8c7-7d4e11b0ec04"
      },
      "source": [
        "!pip install streamlit\r\n",
        "!pip install pyngrok==4.1.1\r\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/3c/f0a97b684a49bd043bef9f8b8f4092b8a25bee9ad9a3f5e121a7161ded8f/streamlit-0.78.0-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.5MB 4.2MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.0.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163kB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/3f/8f04ae0c22d82ec7bec7fcc03270a142f637e362bbd285f7daeeda24fbef/pydeck-0.6.1-py2.py3-none-any.whl (4.6MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.6MB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/ba/a36ca5b4e75649a002f06531862467b3eb5c768caa23d6d88b921fe238d8/watchdog-2.0.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 7.2MB/s \n",
            "\u001b[?25hCollecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (54.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/95/3a670c8b2c2370bd8631c313f42e60983b3113ffec4035940592252bd6d5/ipykernel-5.5.0-py3-none-any.whl (120kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=9fb47e6e9855093d274328d3482d2eddee511dbe1f7a97e83773b4b4a03d3978\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: validators, base58, smmap, gitdb, gitpython, ipykernel, pydeck, watchdog, blinker, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.5 gitpython-3.1.14 ipykernel-5.5.0 pydeck-0.6.1 smmap-3.0.5 streamlit-0.78.0 validators-0.18.2 watchdog-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/a9/de2e15c92eb3aa4a2646ce3a7542317eb69ac47f667578ce8bf916320847/pyngrok-4.1.1.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-cp37-none-any.whl size=15971 sha256=14d9816194e8d13f3400cc913dd14b04cf017d4acbe4e3a23970ad96ca602e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/71/0d/1695f7c8815c0beb3b5d9b35d6eec9243c87e6070fbe3977fa\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZsQhlUpMIuo",
        "outputId": "e282d8f5-dc03-48c7-8478-84eabc165b66"
      },
      "source": [
        "%%writefile app.py\r\n",
        "# Import modules\r\n",
        "import pandas as pd \r\n",
        "import pickle\r\n",
        "import streamlit as st\r\n",
        "import re\r\n",
        "\r\n",
        "# Display on webpage\r\n",
        "st.title('Movie review classification')\r\n",
        "st.markdown(\"This project uses the IMDB movie review dataset\")\r\n",
        "st.markdown(\"Using sentiment analysis, reviews will be classified under a specific category\")\r\n",
        "st.sidebar.title(\"Steps for use: \")\r\n",
        "st.sidebar.markdown(\"1. Write a review in the box\")\r\n",
        "st.sidebar.markdown(\"2. Press enter\")\r\n",
        "st.sidebar.markdown(\"3. Wait for Positive/Negative to appear\")\r\n",
        "st.sidebar.markdown(\"It's that simple!\")\r\n",
        "\r\n",
        "# Load previously created models\r\n",
        "loaded_model = pickle.load(open(\"MNBmodel.pkl\",\"rb\"))\r\n",
        "cv = pickle.load(open(\"countvectorizer.pkl\",\"rb\"))\r\n",
        "\r\n",
        "# Predict output for new review\r\n",
        "def new_review(new_review):\r\n",
        "  new_review = new_review\r\n",
        "  # Replace , by white spaces in the input review\r\n",
        "  new_review = re.sub('[^a-zA-Z]', ' ', new_review)\r\n",
        "  # Convert to lower case\r\n",
        "  new_review = new_review.lower()\r\n",
        "  # Separate words from text in review\r\n",
        "  new_review = new_review.split()\r\n",
        "  # Generate stop words in english\r\n",
        "  all_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\r\n",
        "  # If word in review is not a stop word, add to corpus list\r\n",
        "  new_review = [word for word in new_review if not word in set(all_stopwords)]\r\n",
        "  new_review = ' '.join(new_review)\r\n",
        "  new_corpus = [new_review]\r\n",
        "  # Convert to binary form\r\n",
        "  new_X_test = cv.transform(new_corpus).toarray()\r\n",
        "  # Predict sentiment for review\r\n",
        "  new_y_pred = loaded_model.predict(new_X_test)\r\n",
        "  return new_y_pred\r\n",
        "\r\n",
        "# Take review from user\r\n",
        "input_review = st.text_input('Enter new review:')\r\n",
        "new_review = new_review(input_review)\r\n",
        "# Display results to user\r\n",
        "if new_review[0]==1:\r\n",
        "   st.title(\"Positive\")\r\n",
        "else :\r\n",
        "   st.title(\"Negative\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9P9zPRGvnZ7Y",
        "outputId": "1531242f-028e-4c3d-923f-a4ffe0d1fe19"
      },
      "source": [
        "!nohup streamlit run app.py &\r\n",
        "url = ngrok.connect(port='8501')\r\n",
        "url"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'http://abf7e3e0e5ea.ngrok.io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A2AKdTM5bOC"
      },
      "source": [
        "Generate requirements.txt that contains a list of libraries needed to run this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlK6UwaBnc4-"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXe0yLS15aEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}